{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Model Training\n",
    "\n",
    "In this module, I developed a framework for training multiple models easily with the intent of preventing overfitting. I first make a model pipeline that preprocesses data using standard scaling (b/c scikit learn models prefer normalized data). Then, I create a dictionary of model pipelines for organizational purposes. This would allow me to swap/add different models systematically. Next, I make hyperparameter grids for each model pipeline in order to again have a systematic way of swapping/adding different hyperparameters to tune. I then fit and tune models using 10 fold cross validation, with 20% of the observations used as a validation set. For this project I use 5 models: lasso, ridge, elastic-net, random forest classification, and a gradient boosted tree. \n",
    "\n",
    "Because this is a regression problem, I used r^2 and mean average error as my evaluation metrics. \n",
    "\n",
    "Random Forest gave the best mean average error and r^2. I used the best_estimator method to get the best model parameters for the random forest model. I then saved the model at a .pkl file.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print function ready to serve.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function  # Compatability with Python 3\n",
    "print( 'Print function ready to serve.' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NumPy for numerical computing\n",
    "import numpy as np\n",
    "\n",
    "# Pandas for DataFrames\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "# Matplotlib for visualization\n",
    "from matplotlib import pyplot as plt\n",
    "# display plots in the notebook\n",
    "%matplotlib inline \n",
    "\n",
    "# Seaborn for easier visualization\n",
    "import seaborn as sns\n",
    "\n",
    "# Scikit-Learn for Modeling\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Elastic Net, Ridge Regression, and Lasso Regression\n",
    "from sklearn.linear_model import ElasticNet, Ridge, Lasso\n",
    "\n",
    "# Import Random Forest and Gradient Boosted Trees\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1864, 41)\n"
     ]
    }
   ],
   "source": [
    "# Load cleaned dataset from Module 3\n",
    "df = pd.read_csv('analytical_base_table.csv')\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br id=\"split\">\n",
    "# 1. Split your dataset\n",
    "\n",
    "I split the data to have 20% of observation as a validation set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for splitting training and test set\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create separate object for target variable\n",
    "y = df.tx_price\n",
    "# Create separate object for input features\n",
    "X = df.drop('tx_price', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split X and y into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1491 373 1491 373\n"
     ]
    }
   ],
   "source": [
    "print( len(X_train), len(X_test), len(y_train), len(y_test) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br id=\"pipelines\">\n",
    "# 2. Build model pipelines\n",
    "\n",
    "I put my model pipelines in a dictionary for organizational purposes for when I fit and train the data using cross validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beds</th>\n",
       "      <th>baths</th>\n",
       "      <th>sqft</th>\n",
       "      <th>lot_size</th>\n",
       "      <th>basement</th>\n",
       "      <th>restaurants</th>\n",
       "      <th>groceries</th>\n",
       "      <th>nightlife</th>\n",
       "      <th>cafes</th>\n",
       "      <th>shopping</th>\n",
       "      <th>arts_entertainment</th>\n",
       "      <th>beauty_spas</th>\n",
       "      <th>active_life</th>\n",
       "      <th>median_age</th>\n",
       "      <th>married</th>\n",
       "      <th>college_grad</th>\n",
       "      <th>property_tax</th>\n",
       "      <th>insurance</th>\n",
       "      <th>median_school</th>\n",
       "      <th>num_schools</th>\n",
       "      <th>two_and_two</th>\n",
       "      <th>during_recession</th>\n",
       "      <th>property_age</th>\n",
       "      <th>school_score</th>\n",
       "      <th>exterior_walls_Brick</th>\n",
       "      <th>exterior_walls_Brick veneer</th>\n",
       "      <th>exterior_walls_Combination</th>\n",
       "      <th>exterior_walls_Metal</th>\n",
       "      <th>exterior_walls_Missing</th>\n",
       "      <th>exterior_walls_Other</th>\n",
       "      <th>exterior_walls_Siding (Alum/Vinyl)</th>\n",
       "      <th>exterior_walls_Wood</th>\n",
       "      <th>roof_Asphalt</th>\n",
       "      <th>roof_Composition Shingle</th>\n",
       "      <th>roof_Missing</th>\n",
       "      <th>roof_Other</th>\n",
       "      <th>roof_Shake Shingle</th>\n",
       "      <th>roof_Wood Shake/ Shingles</th>\n",
       "      <th>property_type_Apartment / Condo / Townhouse</th>\n",
       "      <th>property_type_Single-Family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1491.000</td>\n",
       "      <td>1491.000</td>\n",
       "      <td>1491.000</td>\n",
       "      <td>1491.000</td>\n",
       "      <td>1491.000</td>\n",
       "      <td>1491.000</td>\n",
       "      <td>1491.000</td>\n",
       "      <td>1491.000</td>\n",
       "      <td>1491.000</td>\n",
       "      <td>1491.000</td>\n",
       "      <td>1491.000</td>\n",
       "      <td>1491.000</td>\n",
       "      <td>1491.000</td>\n",
       "      <td>1491.000</td>\n",
       "      <td>1491.000</td>\n",
       "      <td>1491.000</td>\n",
       "      <td>1491.000</td>\n",
       "      <td>1491.000</td>\n",
       "      <td>1491.000</td>\n",
       "      <td>1491.000</td>\n",
       "      <td>1491.000</td>\n",
       "      <td>1491.000</td>\n",
       "      <td>1491.000</td>\n",
       "      <td>1491.000</td>\n",
       "      <td>1491.000</td>\n",
       "      <td>1491.000</td>\n",
       "      <td>1491.000</td>\n",
       "      <td>1491.000</td>\n",
       "      <td>1491.000</td>\n",
       "      <td>1491.000</td>\n",
       "      <td>1491.000</td>\n",
       "      <td>1491.000</td>\n",
       "      <td>1491.000</td>\n",
       "      <td>1491.000</td>\n",
       "      <td>1491.000</td>\n",
       "      <td>1491.000</td>\n",
       "      <td>1491.000</td>\n",
       "      <td>1491.000</td>\n",
       "      <td>1491.000</td>\n",
       "      <td>1491.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.434</td>\n",
       "      <td>2.578</td>\n",
       "      <td>2322.384</td>\n",
       "      <td>13245.311</td>\n",
       "      <td>0.882</td>\n",
       "      <td>39.461</td>\n",
       "      <td>4.469</td>\n",
       "      <td>4.944</td>\n",
       "      <td>5.190</td>\n",
       "      <td>39.904</td>\n",
       "      <td>3.360</td>\n",
       "      <td>23.173</td>\n",
       "      <td>15.801</td>\n",
       "      <td>38.633</td>\n",
       "      <td>69.322</td>\n",
       "      <td>65.298</td>\n",
       "      <td>464.195</td>\n",
       "      <td>139.714</td>\n",
       "      <td>6.485</td>\n",
       "      <td>2.801</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.265</td>\n",
       "      <td>24.513</td>\n",
       "      <td>18.027</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.626</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.073</td>\n",
       "      <td>0.932</td>\n",
       "      <td>1300.196</td>\n",
       "      <td>46397.868</td>\n",
       "      <td>0.323</td>\n",
       "      <td>46.138</td>\n",
       "      <td>4.465</td>\n",
       "      <td>8.282</td>\n",
       "      <td>7.334</td>\n",
       "      <td>52.093</td>\n",
       "      <td>4.662</td>\n",
       "      <td>25.757</td>\n",
       "      <td>17.606</td>\n",
       "      <td>6.665</td>\n",
       "      <td>19.924</td>\n",
       "      <td>16.965</td>\n",
       "      <td>229.263</td>\n",
       "      <td>72.195</td>\n",
       "      <td>1.997</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.441</td>\n",
       "      <td>21.223</td>\n",
       "      <td>6.470</td>\n",
       "      <td>0.483</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.484</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>500.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>22.000</td>\n",
       "      <td>11.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>88.000</td>\n",
       "      <td>30.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>1350.000</td>\n",
       "      <td>1563.500</td>\n",
       "      <td>1.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>33.000</td>\n",
       "      <td>58.000</td>\n",
       "      <td>54.000</td>\n",
       "      <td>321.000</td>\n",
       "      <td>94.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>12.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>1910.000</td>\n",
       "      <td>6168.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>22.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>21.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>15.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>38.000</td>\n",
       "      <td>74.000</td>\n",
       "      <td>67.000</td>\n",
       "      <td>425.000</td>\n",
       "      <td>124.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>18.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3002.500</td>\n",
       "      <td>11761.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>57.500</td>\n",
       "      <td>7.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>50.500</td>\n",
       "      <td>5.000</td>\n",
       "      <td>35.000</td>\n",
       "      <td>21.000</td>\n",
       "      <td>43.000</td>\n",
       "      <td>84.000</td>\n",
       "      <td>79.000</td>\n",
       "      <td>569.000</td>\n",
       "      <td>168.500</td>\n",
       "      <td>8.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>39.000</td>\n",
       "      <td>24.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>7842.000</td>\n",
       "      <td>1220551.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>266.000</td>\n",
       "      <td>24.000</td>\n",
       "      <td>53.000</td>\n",
       "      <td>47.000</td>\n",
       "      <td>340.000</td>\n",
       "      <td>35.000</td>\n",
       "      <td>177.000</td>\n",
       "      <td>94.000</td>\n",
       "      <td>69.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>99.000</td>\n",
       "      <td>4508.000</td>\n",
       "      <td>1374.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>113.000</td>\n",
       "      <td>30.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          beds    baths     sqft    lot_size  basement  restaurants  \\\n",
       "count 1491.000 1491.000 1491.000    1491.000  1491.000     1491.000   \n",
       "mean     3.434    2.578 2322.384   13245.311     0.882       39.461   \n",
       "std      1.073    0.932 1300.196   46397.868     0.323       46.138   \n",
       "min      1.000    1.000  500.000       0.000     0.000        0.000   \n",
       "25%      3.000    2.000 1350.000    1563.500     1.000        7.000   \n",
       "50%      4.000    3.000 1910.000    6168.000     1.000       22.000   \n",
       "75%      4.000    3.000 3002.500   11761.000     1.000       57.500   \n",
       "max      5.000    6.000 7842.000 1220551.000     1.000      266.000   \n",
       "\n",
       "       groceries  nightlife    cafes  shopping  arts_entertainment  \\\n",
       "count   1491.000   1491.000 1491.000  1491.000            1491.000   \n",
       "mean       4.469      4.944    5.190    39.904               3.360   \n",
       "std        4.465      8.282    7.334    52.093               4.662   \n",
       "min        0.000      0.000    0.000     0.000               0.000   \n",
       "25%        1.000      0.000    0.000     6.000               0.000   \n",
       "50%        3.000      2.000    3.000    21.000               2.000   \n",
       "75%        7.000      6.000    6.000    50.500               5.000   \n",
       "max       24.000     53.000   47.000   340.000              35.000   \n",
       "\n",
       "       beauty_spas  active_life  median_age  married  college_grad  \\\n",
       "count     1491.000     1491.000    1491.000 1491.000      1491.000   \n",
       "mean        23.173       15.801      38.633   69.322        65.298   \n",
       "std         25.757       17.606       6.665   19.924        16.965   \n",
       "min          0.000        0.000      22.000   11.000         5.000   \n",
       "25%          4.000        4.000      33.000   58.000        54.000   \n",
       "50%         15.000       10.000      38.000   74.000        67.000   \n",
       "75%         35.000       21.000      43.000   84.000        79.000   \n",
       "max        177.000       94.000      69.000  100.000        99.000   \n",
       "\n",
       "       property_tax  insurance  median_school  num_schools  two_and_two  \\\n",
       "count      1491.000   1491.000       1491.000     1491.000     1491.000   \n",
       "mean        464.195    139.714          6.485        2.801        0.093   \n",
       "std         229.263     72.195          1.997        0.496        0.290   \n",
       "min          88.000     30.000          1.000        1.000        0.000   \n",
       "25%         321.000     94.000          5.000        3.000        0.000   \n",
       "50%         425.000    124.000          7.000        3.000        0.000   \n",
       "75%         569.000    168.500          8.000        3.000        0.000   \n",
       "max        4508.000   1374.000         10.000        4.000        1.000   \n",
       "\n",
       "       during_recession  property_age  school_score  exterior_walls_Brick  \\\n",
       "count          1491.000      1491.000      1491.000              1491.000   \n",
       "mean              0.265        24.513        18.027                 0.372   \n",
       "std               0.441        21.223         6.470                 0.483   \n",
       "min               0.000         0.000         3.000                 0.000   \n",
       "25%               0.000         6.000        12.000                 0.000   \n",
       "50%               0.000        20.000        18.000                 0.000   \n",
       "75%               1.000        39.000        24.000                 1.000   \n",
       "max               1.000       113.000        30.000                 1.000   \n",
       "\n",
       "       exterior_walls_Brick veneer  exterior_walls_Combination  \\\n",
       "count                     1491.000                    1491.000   \n",
       "mean                         0.028                       0.058   \n",
       "std                          0.166                       0.234   \n",
       "min                          0.000                       0.000   \n",
       "25%                          0.000                       0.000   \n",
       "50%                          0.000                       0.000   \n",
       "75%                          0.000                       0.000   \n",
       "max                          1.000                       1.000   \n",
       "\n",
       "       exterior_walls_Metal  exterior_walls_Missing  exterior_walls_Other  \\\n",
       "count              1491.000                1491.000              1491.000   \n",
       "mean                  0.059                   0.120                 0.038   \n",
       "std                   0.236                   0.325                 0.190   \n",
       "min                   0.000                   0.000                 0.000   \n",
       "25%                   0.000                   0.000                 0.000   \n",
       "50%                   0.000                   0.000                 0.000   \n",
       "75%                   0.000                   0.000                 0.000   \n",
       "max                   1.000                   1.000                 1.000   \n",
       "\n",
       "       exterior_walls_Siding (Alum/Vinyl)  exterior_walls_Wood  roof_Asphalt  \\\n",
       "count                            1491.000             1491.000      1491.000   \n",
       "mean                                0.258                0.067         0.074   \n",
       "std                                 0.438                0.250         0.261   \n",
       "min                                 0.000                0.000         0.000   \n",
       "25%                                 0.000                0.000         0.000   \n",
       "50%                                 0.000                0.000         0.000   \n",
       "75%                                 1.000                0.000         0.000   \n",
       "max                                 1.000                1.000         1.000   \n",
       "\n",
       "       roof_Composition Shingle  roof_Missing  roof_Other  roof_Shake Shingle  \\\n",
       "count                  1491.000      1491.000    1491.000            1491.000   \n",
       "mean                      0.626         0.189       0.062               0.031   \n",
       "std                       0.484         0.392       0.242               0.173   \n",
       "min                       0.000         0.000       0.000               0.000   \n",
       "25%                       0.000         0.000       0.000               0.000   \n",
       "50%                       1.000         0.000       0.000               0.000   \n",
       "75%                       1.000         0.000       0.000               0.000   \n",
       "max                       1.000         1.000       1.000               1.000   \n",
       "\n",
       "       roof_Wood Shake/ Shingles  property_type_Apartment / Condo / Townhouse  \\\n",
       "count                   1491.000                                     1491.000   \n",
       "mean                       0.018                                        0.422   \n",
       "std                        0.133                                        0.494   \n",
       "min                        0.000                                        0.000   \n",
       "25%                        0.000                                        0.000   \n",
       "50%                        0.000                                        0.000   \n",
       "75%                        0.000                                        1.000   \n",
       "max                        1.000                                        1.000   \n",
       "\n",
       "       property_type_Single-Family  \n",
       "count                     1491.000  \n",
       "mean                         0.578  \n",
       "std                          0.494  \n",
       "min                          0.000  \n",
       "25%                          0.000  \n",
       "50%                          1.000  \n",
       "75%                          1.000  \n",
       "max                          1.000  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary statistics of X_train\n",
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize X_train. Didn't understand the concept of StandardScaler, so I practiced.\n",
    "X_train_new = (X_train-X_train.mean())/(X_train.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beds</th>\n",
       "      <th>baths</th>\n",
       "      <th>sqft</th>\n",
       "      <th>lot_size</th>\n",
       "      <th>basement</th>\n",
       "      <th>restaurants</th>\n",
       "      <th>groceries</th>\n",
       "      <th>nightlife</th>\n",
       "      <th>cafes</th>\n",
       "      <th>shopping</th>\n",
       "      <th>arts_entertainment</th>\n",
       "      <th>beauty_spas</th>\n",
       "      <th>active_life</th>\n",
       "      <th>median_age</th>\n",
       "      <th>married</th>\n",
       "      <th>college_grad</th>\n",
       "      <th>property_tax</th>\n",
       "      <th>insurance</th>\n",
       "      <th>median_school</th>\n",
       "      <th>num_schools</th>\n",
       "      <th>two_and_two</th>\n",
       "      <th>during_recession</th>\n",
       "      <th>property_age</th>\n",
       "      <th>school_score</th>\n",
       "      <th>exterior_walls_Brick</th>\n",
       "      <th>exterior_walls_Brick veneer</th>\n",
       "      <th>exterior_walls_Combination</th>\n",
       "      <th>exterior_walls_Metal</th>\n",
       "      <th>exterior_walls_Missing</th>\n",
       "      <th>exterior_walls_Other</th>\n",
       "      <th>exterior_walls_Siding (Alum/Vinyl)</th>\n",
       "      <th>exterior_walls_Wood</th>\n",
       "      <th>roof_Asphalt</th>\n",
       "      <th>roof_Composition Shingle</th>\n",
       "      <th>roof_Missing</th>\n",
       "      <th>roof_Other</th>\n",
       "      <th>roof_Shake Shingle</th>\n",
       "      <th>roof_Wood Shake/ Shingles</th>\n",
       "      <th>property_type_Apartment / Condo / Townhouse</th>\n",
       "      <th>property_type_Single-Family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1491.000</td>\n",
       "      <td>1491.000</td>\n",
       "      <td>1491.000</td>\n",
       "      <td>1491.000</td>\n",
       "      <td>1491.000</td>\n",
       "      <td>1491.000</td>\n",
       "      <td>1491.000</td>\n",
       "      <td>1491.000</td>\n",
       "      <td>1491.000</td>\n",
       "      <td>1491.000</td>\n",
       "      <td>1491.000</td>\n",
       "      <td>1491.000</td>\n",
       "      <td>1491.000</td>\n",
       "      <td>1491.000</td>\n",
       "      <td>1491.000</td>\n",
       "      <td>1491.000</td>\n",
       "      <td>1491.000</td>\n",
       "      <td>1491.000</td>\n",
       "      <td>1491.000</td>\n",
       "      <td>1491.000</td>\n",
       "      <td>1491.000</td>\n",
       "      <td>1491.000</td>\n",
       "      <td>1491.000</td>\n",
       "      <td>1491.000</td>\n",
       "      <td>1491.000</td>\n",
       "      <td>1491.000</td>\n",
       "      <td>1491.000</td>\n",
       "      <td>1491.000</td>\n",
       "      <td>1491.000</td>\n",
       "      <td>1491.000</td>\n",
       "      <td>1491.000</td>\n",
       "      <td>1491.000</td>\n",
       "      <td>1491.000</td>\n",
       "      <td>1491.000</td>\n",
       "      <td>1491.000</td>\n",
       "      <td>1491.000</td>\n",
       "      <td>1491.000</td>\n",
       "      <td>1491.000</td>\n",
       "      <td>1491.000</td>\n",
       "      <td>1491.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.269</td>\n",
       "      <td>-1.694</td>\n",
       "      <td>-1.402</td>\n",
       "      <td>-0.285</td>\n",
       "      <td>-2.733</td>\n",
       "      <td>-0.855</td>\n",
       "      <td>-1.001</td>\n",
       "      <td>-0.597</td>\n",
       "      <td>-0.708</td>\n",
       "      <td>-0.766</td>\n",
       "      <td>-0.721</td>\n",
       "      <td>-0.900</td>\n",
       "      <td>-0.897</td>\n",
       "      <td>-2.496</td>\n",
       "      <td>-2.927</td>\n",
       "      <td>-3.554</td>\n",
       "      <td>-1.641</td>\n",
       "      <td>-1.520</td>\n",
       "      <td>-2.747</td>\n",
       "      <td>-3.634</td>\n",
       "      <td>-0.319</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>-1.155</td>\n",
       "      <td>-2.322</td>\n",
       "      <td>-0.769</td>\n",
       "      <td>-0.170</td>\n",
       "      <td>-0.249</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>-0.369</td>\n",
       "      <td>-0.197</td>\n",
       "      <td>-0.590</td>\n",
       "      <td>-0.268</td>\n",
       "      <td>-0.282</td>\n",
       "      <td>-1.293</td>\n",
       "      <td>-0.483</td>\n",
       "      <td>-0.258</td>\n",
       "      <td>-0.178</td>\n",
       "      <td>-0.136</td>\n",
       "      <td>-0.854</td>\n",
       "      <td>-1.170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.405</td>\n",
       "      <td>-0.620</td>\n",
       "      <td>-0.748</td>\n",
       "      <td>-0.252</td>\n",
       "      <td>0.366</td>\n",
       "      <td>-0.704</td>\n",
       "      <td>-0.777</td>\n",
       "      <td>-0.597</td>\n",
       "      <td>-0.708</td>\n",
       "      <td>-0.651</td>\n",
       "      <td>-0.721</td>\n",
       "      <td>-0.744</td>\n",
       "      <td>-0.670</td>\n",
       "      <td>-0.845</td>\n",
       "      <td>-0.568</td>\n",
       "      <td>-0.666</td>\n",
       "      <td>-0.625</td>\n",
       "      <td>-0.633</td>\n",
       "      <td>-0.744</td>\n",
       "      <td>0.402</td>\n",
       "      <td>-0.319</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>-0.872</td>\n",
       "      <td>-0.932</td>\n",
       "      <td>-0.769</td>\n",
       "      <td>-0.170</td>\n",
       "      <td>-0.249</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>-0.369</td>\n",
       "      <td>-0.197</td>\n",
       "      <td>-0.590</td>\n",
       "      <td>-0.268</td>\n",
       "      <td>-0.282</td>\n",
       "      <td>-1.293</td>\n",
       "      <td>-0.483</td>\n",
       "      <td>-0.258</td>\n",
       "      <td>-0.178</td>\n",
       "      <td>-0.136</td>\n",
       "      <td>-0.854</td>\n",
       "      <td>-1.170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.528</td>\n",
       "      <td>0.453</td>\n",
       "      <td>-0.317</td>\n",
       "      <td>-0.153</td>\n",
       "      <td>0.366</td>\n",
       "      <td>-0.378</td>\n",
       "      <td>-0.329</td>\n",
       "      <td>-0.355</td>\n",
       "      <td>-0.299</td>\n",
       "      <td>-0.363</td>\n",
       "      <td>-0.292</td>\n",
       "      <td>-0.317</td>\n",
       "      <td>-0.329</td>\n",
       "      <td>-0.095</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.100</td>\n",
       "      <td>-0.171</td>\n",
       "      <td>-0.218</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0.402</td>\n",
       "      <td>-0.319</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>-0.213</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.769</td>\n",
       "      <td>-0.170</td>\n",
       "      <td>-0.249</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>-0.369</td>\n",
       "      <td>-0.197</td>\n",
       "      <td>-0.590</td>\n",
       "      <td>-0.268</td>\n",
       "      <td>-0.282</td>\n",
       "      <td>0.773</td>\n",
       "      <td>-0.483</td>\n",
       "      <td>-0.258</td>\n",
       "      <td>-0.178</td>\n",
       "      <td>-0.136</td>\n",
       "      <td>-0.854</td>\n",
       "      <td>0.854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.528</td>\n",
       "      <td>0.453</td>\n",
       "      <td>0.523</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.391</td>\n",
       "      <td>0.567</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.459</td>\n",
       "      <td>0.295</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.457</td>\n",
       "      <td>0.399</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.402</td>\n",
       "      <td>-0.319</td>\n",
       "      <td>1.665</td>\n",
       "      <td>0.683</td>\n",
       "      <td>0.923</td>\n",
       "      <td>1.300</td>\n",
       "      <td>-0.170</td>\n",
       "      <td>-0.249</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>-0.369</td>\n",
       "      <td>-0.197</td>\n",
       "      <td>1.694</td>\n",
       "      <td>-0.268</td>\n",
       "      <td>-0.282</td>\n",
       "      <td>0.773</td>\n",
       "      <td>-0.483</td>\n",
       "      <td>-0.258</td>\n",
       "      <td>-0.178</td>\n",
       "      <td>-0.136</td>\n",
       "      <td>1.170</td>\n",
       "      <td>0.854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.460</td>\n",
       "      <td>3.672</td>\n",
       "      <td>4.245</td>\n",
       "      <td>26.021</td>\n",
       "      <td>0.366</td>\n",
       "      <td>4.910</td>\n",
       "      <td>4.374</td>\n",
       "      <td>5.802</td>\n",
       "      <td>5.701</td>\n",
       "      <td>5.761</td>\n",
       "      <td>6.786</td>\n",
       "      <td>5.972</td>\n",
       "      <td>4.442</td>\n",
       "      <td>4.556</td>\n",
       "      <td>1.540</td>\n",
       "      <td>1.987</td>\n",
       "      <td>17.638</td>\n",
       "      <td>17.097</td>\n",
       "      <td>1.760</td>\n",
       "      <td>2.420</td>\n",
       "      <td>3.130</td>\n",
       "      <td>1.665</td>\n",
       "      <td>4.169</td>\n",
       "      <td>1.850</td>\n",
       "      <td>1.300</td>\n",
       "      <td>5.872</td>\n",
       "      <td>4.016</td>\n",
       "      <td>3.992</td>\n",
       "      <td>2.706</td>\n",
       "      <td>5.060</td>\n",
       "      <td>1.694</td>\n",
       "      <td>3.728</td>\n",
       "      <td>3.542</td>\n",
       "      <td>0.773</td>\n",
       "      <td>2.070</td>\n",
       "      <td>3.876</td>\n",
       "      <td>5.603</td>\n",
       "      <td>7.361</td>\n",
       "      <td>1.170</td>\n",
       "      <td>0.854</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          beds    baths     sqft  lot_size  basement  restaurants  groceries  \\\n",
       "count 1491.000 1491.000 1491.000  1491.000  1491.000     1491.000   1491.000   \n",
       "mean    -0.000   -0.000    0.000    -0.000    -0.000       -0.000      0.000   \n",
       "std      1.000    1.000    1.000     1.000     1.000        1.000      1.000   \n",
       "min     -2.269   -1.694   -1.402    -0.285    -2.733       -0.855     -1.001   \n",
       "25%     -0.405   -0.620   -0.748    -0.252     0.366       -0.704     -0.777   \n",
       "50%      0.528    0.453   -0.317    -0.153     0.366       -0.378     -0.329   \n",
       "75%      0.528    0.453    0.523    -0.032     0.366        0.391      0.567   \n",
       "max      1.460    3.672    4.245    26.021     0.366        4.910      4.374   \n",
       "\n",
       "       nightlife    cafes  shopping  arts_entertainment  beauty_spas  \\\n",
       "count   1491.000 1491.000  1491.000            1491.000     1491.000   \n",
       "mean       0.000   -0.000     0.000              -0.000        0.000   \n",
       "std        1.000    1.000     1.000               1.000        1.000   \n",
       "min       -0.597   -0.708    -0.766              -0.721       -0.900   \n",
       "25%       -0.597   -0.708    -0.651              -0.721       -0.744   \n",
       "50%       -0.355   -0.299    -0.363              -0.292       -0.317   \n",
       "75%        0.128    0.110     0.203               0.352        0.459   \n",
       "max        5.802    5.701     5.761               6.786        5.972   \n",
       "\n",
       "       active_life  median_age  married  college_grad  property_tax  \\\n",
       "count     1491.000    1491.000 1491.000      1491.000      1491.000   \n",
       "mean        -0.000       0.000   -0.000        -0.000        -0.000   \n",
       "std          1.000       1.000    1.000         1.000         1.000   \n",
       "min         -0.897      -2.496   -2.927        -3.554        -1.641   \n",
       "25%         -0.670      -0.845   -0.568        -0.666        -0.625   \n",
       "50%         -0.329      -0.095    0.235         0.100        -0.171   \n",
       "75%          0.295       0.655    0.737         0.808         0.457   \n",
       "max          4.442       4.556    1.540         1.987        17.638   \n",
       "\n",
       "       insurance  median_school  num_schools  two_and_two  during_recession  \\\n",
       "count   1491.000       1491.000     1491.000     1491.000          1491.000   \n",
       "mean       0.000          0.000       -0.000        0.000             0.000   \n",
       "std        1.000          1.000        1.000        1.000             1.000   \n",
       "min       -1.520         -2.747       -3.634       -0.319            -0.600   \n",
       "25%       -0.633         -0.744        0.402       -0.319            -0.600   \n",
       "50%       -0.218          0.258        0.402       -0.319            -0.600   \n",
       "75%        0.399          0.758        0.402       -0.319             1.665   \n",
       "max       17.097          1.760        2.420        3.130             1.665   \n",
       "\n",
       "       property_age  school_score  exterior_walls_Brick  \\\n",
       "count      1491.000      1491.000              1491.000   \n",
       "mean         -0.000        -0.000                -0.000   \n",
       "std           1.000         1.000                 1.000   \n",
       "min          -1.155        -2.322                -0.769   \n",
       "25%          -0.872        -0.932                -0.769   \n",
       "50%          -0.213        -0.004                -0.769   \n",
       "75%           0.683         0.923                 1.300   \n",
       "max           4.169         1.850                 1.300   \n",
       "\n",
       "       exterior_walls_Brick veneer  exterior_walls_Combination  \\\n",
       "count                     1491.000                    1491.000   \n",
       "mean                        -0.000                       0.000   \n",
       "std                          1.000                       1.000   \n",
       "min                         -0.170                      -0.249   \n",
       "25%                         -0.170                      -0.249   \n",
       "50%                         -0.170                      -0.249   \n",
       "75%                         -0.170                      -0.249   \n",
       "max                          5.872                       4.016   \n",
       "\n",
       "       exterior_walls_Metal  exterior_walls_Missing  exterior_walls_Other  \\\n",
       "count              1491.000                1491.000              1491.000   \n",
       "mean                  0.000                  -0.000                 0.000   \n",
       "std                   1.000                   1.000                 1.000   \n",
       "min                  -0.250                  -0.369                -0.197   \n",
       "25%                  -0.250                  -0.369                -0.197   \n",
       "50%                  -0.250                  -0.369                -0.197   \n",
       "75%                  -0.250                  -0.369                -0.197   \n",
       "max                   3.992                   2.706                 5.060   \n",
       "\n",
       "       exterior_walls_Siding (Alum/Vinyl)  exterior_walls_Wood  roof_Asphalt  \\\n",
       "count                            1491.000             1491.000      1491.000   \n",
       "mean                                0.000               -0.000         0.000   \n",
       "std                                 1.000                1.000         1.000   \n",
       "min                                -0.590               -0.268        -0.282   \n",
       "25%                                -0.590               -0.268        -0.282   \n",
       "50%                                -0.590               -0.268        -0.282   \n",
       "75%                                 1.694               -0.268        -0.282   \n",
       "max                                 1.694                3.728         3.542   \n",
       "\n",
       "       roof_Composition Shingle  roof_Missing  roof_Other  roof_Shake Shingle  \\\n",
       "count                  1491.000      1491.000    1491.000            1491.000   \n",
       "mean                      0.000        -0.000      -0.000               0.000   \n",
       "std                       1.000         1.000       1.000               1.000   \n",
       "min                      -1.293        -0.483      -0.258              -0.178   \n",
       "25%                      -1.293        -0.483      -0.258              -0.178   \n",
       "50%                       0.773        -0.483      -0.258              -0.178   \n",
       "75%                       0.773        -0.483      -0.258              -0.178   \n",
       "max                       0.773         2.070       3.876               5.603   \n",
       "\n",
       "       roof_Wood Shake/ Shingles  property_type_Apartment / Condo / Townhouse  \\\n",
       "count                   1491.000                                     1491.000   \n",
       "mean                      -0.000                                        0.000   \n",
       "std                        1.000                                        1.000   \n",
       "min                       -0.136                                       -0.854   \n",
       "25%                       -0.136                                       -0.854   \n",
       "50%                       -0.136                                       -0.854   \n",
       "75%                       -0.136                                        1.170   \n",
       "max                        7.361                                        1.170   \n",
       "\n",
       "       property_type_Single-Family  \n",
       "count                     1491.000  \n",
       "mean                        -0.000  \n",
       "std                          1.000  \n",
       "min                         -1.170  \n",
       "25%                         -1.170  \n",
       "50%                          0.854  \n",
       "75%                          0.854  \n",
       "max                          0.854  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary statistics of X_train_new\n",
    "X_train_new.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for creating model pipelines\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For standardization\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipelines dictionary\n",
    "pipelines = {\n",
    "    'lasso': make_pipeline(StandardScaler(), Lasso(random_state=123)),\n",
    "    'ridge': make_pipeline(StandardScaler(), Ridge(random_state=123)),\n",
    "    'enet': make_pipeline(StandardScaler(), ElasticNet(random_state=123))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a pipeline for 'rf'\n",
    "pipelines['rf'] = make_pipeline(StandardScaler(), RandomForestRegressor(random_state=123))\n",
    "# Add a pipeline for 'gb'\n",
    "pipelines['gb'] = make_pipeline(StandardScaler(), GradientBoostingRegressor(random_state=123))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso <class 'sklearn.pipeline.Pipeline'>\n",
      "ridge <class 'sklearn.pipeline.Pipeline'>\n",
      "enet <class 'sklearn.pipeline.Pipeline'>\n",
      "rf <class 'sklearn.pipeline.Pipeline'>\n",
      "gb <class 'sklearn.pipeline.Pipeline'>\n"
     ]
    }
   ],
   "source": [
    "# Check that we have all 5 algorithms, and that they are all pipelines\n",
    "for key, value in pipelines.items():\n",
    "    print( key, type(value) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br id=\"hyperparameters\">\n",
    "# 3. Declare hyperparameters to tune\n",
    "\n",
    "I make a hyperparameter grid for each model I'd like to train. I then put these grids in a \"hyperparameters\" dictionary for organizational purposes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('standardscaler',\n",
       "   StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "  ('lasso', Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "      normalize=False, positive=False, precompute=False, random_state=123,\n",
       "      selection='cyclic', tol=0.0001, warm_start=False))],\n",
       " 'standardscaler': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'lasso': Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "    normalize=False, positive=False, precompute=False, random_state=123,\n",
       "    selection='cyclic', tol=0.0001, warm_start=False),\n",
       " 'standardscaler__copy': True,\n",
       " 'standardscaler__with_mean': True,\n",
       " 'standardscaler__with_std': True,\n",
       " 'lasso__alpha': 1.0,\n",
       " 'lasso__copy_X': True,\n",
       " 'lasso__fit_intercept': True,\n",
       " 'lasso__max_iter': 1000,\n",
       " 'lasso__normalize': False,\n",
       " 'lasso__positive': False,\n",
       " 'lasso__precompute': False,\n",
       " 'lasso__random_state': 123,\n",
       " 'lasso__selection': 'cyclic',\n",
       " 'lasso__tol': 0.0001,\n",
       " 'lasso__warm_start': False}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List tuneable hyperparameters of our Lasso pipeline\n",
    "pipelines['lasso'].get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso hyperparameters\n",
    "lasso_hyperparameters = {\n",
    "    'lasso__alpha': [0.001,0.005,0.01,0.05,0.1,0.5,1,5,10]\n",
    "}\n",
    "# Ridge hyperparameters\n",
    "ridge_hyperparameters={\n",
    "    'ridge__alpha': [0.001,0.005,0.01,0.05,0.1,0.5,1,5,10]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elastic Net hyperparameters\n",
    "enet_hyperparameters={\n",
    "    'elasticnet__alpha': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10],\n",
    "    'elasticnet__l1_ratio' : [0.1, 0.3, 0.5, 0.7, 0.9]  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest hyperparameters\n",
    "rf_hyperparameters = {\n",
    "    'randomforestregressor__n_estimators': [100, 200],\n",
    "    'randomforestregressor__max_features': ['auto', 'sqrt', 0.33]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boosted tree hyperparameters\n",
    "gb_hyperparameters = {\n",
    "    'gradientboostingregressor__n_estimators':[100,200],\n",
    "    'gradientboostingregressor__learning_rate':[0.05,0.2,0.2],\n",
    "    'gradientboostingregressor__max_depth':[1,3,5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create hyperparameters dictionary\n",
    "hyperparameters = {\n",
    "    'lasso': lasso_hyperparameters,\n",
    "    'ridge': ridge_hyperparameters,\n",
    "    'enet': enet_hyperparameters,\n",
    "    'rf': rf_hyperparameters,\n",
    "    'gb': gb_hyperparameters\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet was found in hyperparameters, and it is a grid.\n",
      "gb was found in hyperparameters, and it is a grid.\n",
      "ridge was found in hyperparameters, and it is a grid.\n",
      "rf was found in hyperparameters, and it is a grid.\n",
      "lasso was found in hyperparameters, and it is a grid.\n"
     ]
    }
   ],
   "source": [
    "for key in ['enet', 'gb', 'ridge', 'rf', 'lasso']:\n",
    "    if key in hyperparameters:\n",
    "        if type(hyperparameters[key]) is dict:\n",
    "            print( key, 'was found in hyperparameters, and it is a grid.' )\n",
    "        else:\n",
    "            print( key, 'was found in hyperparameters, but it is not a grid.' )\n",
    "    else:\n",
    "        print( key, 'was not found in hyperparameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br id=\"fit-tune\">\n",
    "# 4. Fit and tune models with cross-validation\n",
    "\n",
    "This is the part where the existence of hyperparameters and model pipelines dictionaries comes into play. By making these dictionaries, I can make a for loop that iterates through the pipelines dictionaries, and inputs the hyperparameter grid and model pipeline for each model into its associated GridSearchCV object. This results in an elegant way to cross validate many model pipelines. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper for cross-validation\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create cross-validation object from Lasso pipeline and Lasso hyperparameters\n",
    "model = GridSearchCV(pipelines['lasso'], hyperparameters['lasso'], cv=10,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter randomforestregressor for estimator Pipeline(memory=None,\n     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('lasso', Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n   normalize=False, positive=False, precompute=False, random_state=123,\n   selection='cyclic', tol=0.0001, warm_start=False))]). Check the list of available parameters with `estimator.get_params().keys()`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\users\\toshiba\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\externals\\loky\\process_executor.py\", line 420, in _process_worker\n    r = call_item.fn(*call_item.args, **call_item.kwargs)\n  File \"c:\\users\\toshiba\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 563, in __call__\n    return self.func(*args, **kwargs)\n  File \"c:\\users\\toshiba\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 261, in __call__\n    for func, args, kwargs in self.items]\n  File \"c:\\users\\toshiba\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 261, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"c:\\users\\toshiba\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 514, in _fit_and_score\n    estimator.set_params(**parameters)\n  File \"c:\\users\\toshiba\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\pipeline.py\", line 147, in set_params\n    self._set_params('steps', **kwargs)\n  File \"c:\\users\\toshiba\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 52, in _set_params\n    super(_BaseComposition, self).set_params(**params)\n  File \"c:\\users\\toshiba\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\base.py\", line 213, in set_params\n    (key, self))\nValueError: Invalid parameter randomforestregressor for estimator Pipeline(memory=None,\n     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('lasso', Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n   normalize=False, positive=False, precompute=False, random_state=123,\n   selection='cyclic', tol=0.0001, warm_start=False))]). Check the list of available parameters with `estimator.get_params().keys()`.\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-65-b28e4b64a2d2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Fit and tune model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\toshiba\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    720\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\toshiba\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1189\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1191\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\toshiba\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    709\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 711\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    712\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\toshiba\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    994\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    995\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 996\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    997\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    998\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\toshiba\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    897\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    898\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 899\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    900\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    901\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\toshiba\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    515\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    516\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 517\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    518\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\toshiba\\appdata\\local\\programs\\python\\python36\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    403\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 405\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    406\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\toshiba\\appdata\\local\\programs\\python\\python36\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    355\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 357\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    358\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid parameter randomforestregressor for estimator Pipeline(memory=None,\n     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('lasso', Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n   normalize=False, positive=False, precompute=False, random_state=123,\n   selection='cyclic', tol=0.0001, warm_start=False))]). Check the list of available parameters with `estimator.get_params().keys()`."
     ]
    }
   ],
   "source": [
    "# Fit and tune model\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['lasso', 'ridge', 'enet', 'rf', 'gb'])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipelines.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\toshiba\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "c:\\users\\toshiba\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\data.py:617: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "c:\\users\\toshiba\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso has been fitted.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\toshiba\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "c:\\users\\toshiba\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\data.py:617: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "c:\\users\\toshiba\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ridge has been fitted.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\toshiba\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "c:\\users\\toshiba\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\data.py:617: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "c:\\users\\toshiba\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet has been fitted.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\toshiba\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\data.py:617: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "c:\\users\\toshiba\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf has been fitted.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\toshiba\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\data.py:617: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "c:\\users\\toshiba\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gb has been fitted.\n"
     ]
    }
   ],
   "source": [
    "# Create empty dictionary called fitted_models\n",
    "fitted_models = {}\n",
    "\n",
    "# Loop through model pipelines, tuning each one and saving it to fitted_models\n",
    "for name, pipeline in pipelines.items():\n",
    "    # Create cross-validation object from pipeline and hyperparameters\n",
    "    model = GridSearchCV(pipeline, hyperparameters[name], cv=10, n_jobs=-1)\n",
    "    \n",
    "    # Fit model on X_train, y_train\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Store model in fitted_models[name] \n",
    "    fitted_models[name] = model\n",
    "    \n",
    "    # Print '{name} has been fitted'\n",
    "    print(name, 'has been fitted.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso <class 'sklearn.model_selection._search.GridSearchCV'>\n",
      "ridge <class 'sklearn.model_selection._search.GridSearchCV'>\n",
      "enet <class 'sklearn.model_selection._search.GridSearchCV'>\n",
      "rf <class 'sklearn.model_selection._search.GridSearchCV'>\n",
      "gb <class 'sklearn.model_selection._search.GridSearchCV'>\n"
     ]
    }
   ],
   "source": [
    "# Check that we have 5 cross-validation objects\n",
    "for key, value in fitted_models.items():\n",
    "    print( key, type(value) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso has been fitted.\n",
      "ridge has been fitted.\n",
      "enet has been fitted.\n",
      "rf has been fitted.\n",
      "gb has been fitted.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\toshiba\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "c:\\users\\toshiba\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "c:\\users\\toshiba\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "c:\\users\\toshiba\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "c:\\users\\toshiba\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.exceptions import NotFittedError\n",
    "\n",
    "for name, model in fitted_models.items():\n",
    "    try:\n",
    "        pred = model.predict(X_test)\n",
    "        print(name, 'has been fitted.')\n",
    "    except NotFittedError as e:\n",
    "        print(repr(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br id=\"evaluate\">\n",
    "# 5. Evaluate models and select winner\n",
    "\n",
    "Metrics used: Mean average error and R^2. Wanted to find model with the lowest mean average error and the highest R^2. Picked that model as best. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso 0.32073342671068134\n",
      "ridge 0.3259795135456992\n",
      "enet 0.3527117995451829\n",
      "rf 0.5069561736890409\n",
      "gb 0.5104830486073169\n"
     ]
    }
   ],
   "source": [
    "# Display best_score_ for each fitted model\n",
    "for name, model in fitted_models.items():\n",
    "    print(name, model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import r2_score and mean_absolute_error functions\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('randomforestregressor', RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "  ...rs='warn', n_jobs=None,\n",
       "           oob_score=False, random_state=123, verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'randomforestregressor__n_estimators': [100, 200], 'randomforestregressor__max_features': ['auto', 'sqrt', 0.33]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display fitted random forest object\n",
    "fitted_models['rf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\toshiba\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    }
   ],
   "source": [
    "# Predict test set using fitted random forest\n",
    "pred = fitted_models['rf'].predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2:  0.4654409568626009\n",
      "MAE:  79495.25798927614\n"
     ]
    }
   ],
   "source": [
    "# Calculate and print R^2 and MAE\n",
    "print('R^2: ', r2_score(y_test, pred))\n",
    "print('MAE: ', mean_absolute_error(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso\n",
      "R^2:  0.35464010508409805\n",
      "MAE:  93818.65569328083\n",
      "ridge\n",
      "R^2:  0.35634533435114657\n",
      "MAE:  93716.244958099\n",
      "enet\n",
      "R^2:  0.35952039769324595\n",
      "MAE:  94108.19906453215\n",
      "rf\n",
      "R^2:  0.4654409568626009\n",
      "MAE:  79495.25798927614\n",
      "gb\n",
      "R^2:  0.4575713364248166\n",
      "MAE:  78712.51869564646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\toshiba\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "c:\\users\\toshiba\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "c:\\users\\toshiba\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "c:\\users\\toshiba\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "c:\\users\\toshiba\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    }
   ],
   "source": [
    "# Code here\n",
    "for name, model in fitted_models.items():\n",
    "    pred = model.predict(X_test)\n",
    "    print(name)\n",
    "    print('R^2: ', r2_score(y_test, pred))\n",
    "    print('MAE: ', mean_absolute_error(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\toshiba\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gb_pred = fitted_models['rf'].predict(X_test)\n",
    "plt.scatter(gb_pred, y_test)\n",
    "plt.xlabel('predicted')\n",
    "plt.ylabel('actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.model_selection._search.GridSearchCV"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(fitted_models['rf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.pipeline.Pipeline"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(fitted_models['rf'].best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('randomforestregressor', RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=None,\n",
       "           oob_score=False, random_state=123, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted_models['rf'].best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " winning values for hyperparameters are:\n",
    "* <code style=\"color:steelblue\">n_estimators: <span style=\"color:crimson\">200</span></code>\n",
    "* <code style=\"color:steelblue\">max_features : <span style=\"color:crimson\">'auto'</span></code>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('final_model.pkl', 'wb') as f:\n",
    "    pickle.dump(fitted_models['rf'].best_estimator_, f)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
